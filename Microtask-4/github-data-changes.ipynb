{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microtask 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aim\n",
    "\n",
    "Produce a listing of repositories, as a table and as CSV file, with the number of commits authored, issues opened, and pull/merge requests opened, during the last three months, ordered by the total number (commits plus issues plus pull requests). Use plain Python3 (eg, no Pandas) for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieving Data from Different Repositories\n",
    "\n",
    "Rather than retrieving data from Default Since Date, it would be better to retrieve data for last 3 months only by providing --from-date argument while retrieving data using perceveal. <br>  \n",
    "From the command line run Perceval on the github repositories to analyze, to produce a file with JSON documents for all its issues (the list obtained contains the pull request also), one per line (data-source.json).\n",
    "\n",
    "\n",
    "Syntax for using Perceval for Github\n",
    "`perceval github owner repository [--sleep-for-rate] [-t XXXXX]`\n",
    "\n",
    "\n",
    "Date of Retrieval: 25st March 2019\n",
    "##### Example:\n",
    "\n",
    "`perceval github --from-date \"2018-12-01\" omegaup omegaup --category issue --sleep-for-rate -t a247a6b7d506736da6d653cddc060a96bfbd9cb3 >> data_source.json`\n",
    "\n",
    "`perceval github --from-date \"2018-12-01\" omegaup omegaup --category pull_request --sleep-for-rate -t a247a6b7d506736da6d653cddc060a96bfbd9cb3 >> data_source.json`      \n",
    "\n",
    "`perceval git --json-line https://github.com/omegaup/omegaup >> data_source.json`\n",
    "\n",
    "\n",
    "`perceval github --from-date \"2018-12-01\" Submitty Submitty --category issue --sleep-for-rate -t a247a6b7d506736da6d653cddc060a96bfbd9cb3 >> data_source.json`\n",
    "\n",
    "`perceval github --from-date \"2018-12-01\" Submitty Submitty --category pull_request --sleep-for-rate -t a247a6b7d506736da6d653cddc060a96bfbd9cb3 >> data_source.json`  \n",
    "\n",
    "`perceval git --json-line https://github.com/Submitty/Submitty >> data_source.json`\n",
    "\n",
    "`perceval github --from-date \"2018-12-01\" streetmix streetmix --category issue --sleep-for-rate -t a247a6b7d506736da6d653cddc060a96bfbd9cb3 >> data_source.json`      \n",
    "\n",
    "`perceval github --from-date \"2018-12-01\" streetmix streetmix --category pull_request --sleep-for-rate -t a247a6b7d506736da6d653cddc060a96bfbd9cb3 >> data_source.json`      \n",
    "\n",
    "`perceval git --json-line https://github.com/streetmix/streetmix >> data_source.json`\n",
    "\n",
    "`perceval github --from-date \"2018-12-01\" fossasia susi_server --category issue --sleep-for-rate -t a247a6b7d506736da6d653cddc060a96bfbd9cb3 >> data_source.json`      \n",
    "\n",
    "`perceval github --from-date \"2018-12-01\" fossasia susi_server --category pull_request --sleep-for-rate -t a247a6b7d506736da6d653cddc060a96bfbd9cb3 >> data_source.json`     \n",
    "\n",
    "`perceval git --json-line https://github.com/fossasia/susi_server >> data_source.json`\n",
    "\n",
    "----------------------------------------------------------------------------------------------------\n",
    "--from-date fetch items updated since this date\n",
    "\n",
    "--sleep-for-rate To avoid having perceval exiting when the rate limit is exceeded\n",
    "\n",
    "-t is token for Github API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import datetime\n",
    "import dateutil.relativedelta\n",
    "import re\n",
    "from copy import deepcopy\n",
    "from dateutil import parser\n",
    "import pandas as pd\n",
    "\n",
    "import warnings ## to ignore warnings that come in importing pandas\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summarize Function\n",
    "\n",
    "#### @arguments \n",
    "\n",
    "<b>line</b>: item to be summarized<br>\n",
    "<b>type</b>: type of item(commit,issue,pull_request)\n",
    "\n",
    "summary{\n",
    "    repo,<br>\n",
    "    hash(in case of commit) or uuid(in case of PR or Issue),<br>\n",
    "    author,<br>\n",
    "    author_date,<br>\n",
    "    ....<br>\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(line,type):\n",
    "    repo = line['origin']\n",
    "    cdata = line['data']\n",
    "    if(type=='commit'):    \n",
    "        summary = {\n",
    "                'repo': repo,\n",
    "                'hash': cdata['commit'],\n",
    "                'author': cdata['Author'],\n",
    "                'author_date': datetime.datetime.strptime(cdata['AuthorDate'],\n",
    "                                                          \"%a %b %d %H:%M:%S %Y %z\"),\n",
    "                'commit': cdata['Commit'],\n",
    "                'created_date': datetime.datetime.strptime(cdata['CommitDate'],\n",
    "                                                          \"%a %b %d %H:%M:%S %Y %z\"),\n",
    "                'files_no': len(cdata['files']),\n",
    "        }\n",
    "        actions = 0\n",
    "        for file in cdata['files']:\n",
    "            if 'action' in file:\n",
    "                actions += 1\n",
    "        summary['files_action'] = actions\n",
    "        if 'Merge' in cdata:\n",
    "            summary['merge'] = True\n",
    "        else:\n",
    "            summary['merge'] = False\n",
    "    elif(type=='issue'):\n",
    "        summary = {\n",
    "                'repo': repo,\n",
    "                'uuid': line['uuid'],\n",
    "                'author': cdata['user']['login'],\n",
    "                'created_date': datetime.datetime.strptime(cdata['created_at'],\n",
    "                                            \"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                'closed_date':datetime.datetime.strptime(cdata['closed_at'],\n",
    "                                            \"%Y-%m-%dT%H:%M:%SZ\") if cdata['closed_at'] else None, \n",
    "                'comments': cdata['comments'],\n",
    "                'labels': cdata['labels'],\n",
    "                'url': cdata['html_url'],\n",
    "                'state':cdata['state']\n",
    "        }\n",
    "    elif(type=='pull_request'):\n",
    "        summary = {\n",
    "                'repo': repo,\n",
    "                'uuid': line['uuid'],\n",
    "                'author': cdata['user']['login'],\n",
    "                'created_date': datetime.datetime.strptime(cdata['created_at'],\"%Y-%m-%dT%H:%M:%SZ\"),\n",
    "                'closed_date': datetime.datetime.strptime(cdata['closed_at'],\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "                                            if cdata['closed_at'] else None,\n",
    "                'merged_date': datetime.datetime.strptime(cdata['merged_at'],\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "                                        if cdata['merged_at'] else None,\n",
    "                'comments': cdata['comments'],\n",
    "                'commits': cdata['commits'],\n",
    "                'additions': cdata['additions'],\n",
    "                'deletions': cdata['deletions'],\n",
    "                'changed_files':cdata['changed_files'],\n",
    "                'url': cdata['html_url'],\n",
    "                'state':cdata['state']\n",
    "        }\n",
    "    \n",
    "    return summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Code_Changes\n",
    "\n",
    "Takes path to the JSON file as input parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Code_Changes:\n",
    "    \"\"\"\"Class for Code_Changes for Git repositories.\n",
    "    \n",
    "    Objects are instantiated by specifying a file with the\n",
    "    commits obtained by Perceval from a set of repositories.\n",
    "    \n",
    "    Contains individual list for Issues, Pull Requests and Commits\n",
    "        \n",
    "    :param path: Path to file with one Perceval JSON document per line\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path):\n",
    "        \n",
    "        self.changes = {'issue':[],'commit':[],'pull_request':[]}\n",
    "        with open(path) as data_file:\n",
    "            for data in data_file:\n",
    "                line = json.loads(data)\n",
    "                if(line['category'] ==  'commit'):\n",
    "                    self.changes['commit'].append(summarize(line,'commit'))\n",
    "                else:\n",
    "                    if (line['category'] == 'pull_request'):\n",
    "                        self.changes['pull_request'].append(summarize(line,'pull_request'))\n",
    "                    elif ('pull_request' not in line['data']) and (line['category'] == 'issue'):\n",
    "                        self.changes['issue'].append(summarize(line,'issue'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = Code_Changes('../../data_source2.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Set Of Repositories\n",
    "\n",
    "intialize a set, iterate over all items and add repo to the set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = set()\n",
    "for change_type,items in code.changes.items():\n",
    "    for item in items:\n",
    "        repos.add(item['repo'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of Repos :\n",
      "---------------\n",
      "https://github.com/streetmix/streetmix\n",
      "https://github.com/fossasia/susi_server\n",
      "https://github.com/omegaup/omegaup\n",
      "https://github.com/Submitty/Submitty\n"
     ]
    }
   ],
   "source": [
    "print(\"List of Repos :\")\n",
    "print(\"---------------\")\n",
    "for i in repos:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysing Data for Last Three Months\n",
    "\n",
    "Last three months (doesn't include current month) [Dec 2018, Jan 2019, Feb 2019]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last third month first Date:  2019-01-01\n",
      "Current month first Date:  2019-04-01\n"
     ]
    }
   ],
   "source": [
    "today_date = datetime.datetime.now().date()\n",
    "last_third_month = today_date - dateutil.relativedelta.relativedelta(months=3)\n",
    "last_third_month_first_date = last_third_month.replace(day=1)\n",
    "current_month_first_date = today_date.replace(day=1)\n",
    "print(\"Last third month first Date: \",last_third_month_first_date)\n",
    "print(\"Current month first Date: \",current_month_first_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to analyse data between the above dates\n",
    "\n",
    "Iterating over each item for each category and adding to a dictionary of repos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis is a dictionary with key named as repo url mapped to a dictionary that has issue, commit and pull_request\n",
    "\n",
    "`Analysis: \n",
    "{\n",
    "\"repo1\":{'issue':x1,'commit':y1,'pull_request':z1},\n",
    "\"repo1\":{'issue':x2,'commit':y2,'pull_request':z2},\n",
    "\"repo1\":{'issue':x3,'commit':y3,'pull_request':z3},\n",
    "}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "since = last_third_month_first_date\n",
    "until = current_month_first_date\n",
    "\n",
    "analysis = {}\n",
    "for i in repos:\n",
    "    analysis[i] = {'issue':0,'commit':0,'pull_request':0}\n",
    "for change_type,items in code.changes.items():\n",
    "    if(change_type=='issue'):\n",
    "        for item in items:\n",
    "            if item['state']=='open':\n",
    "                if since<=item['created_date'].date()<=until:\n",
    "                    analysis[item['repo']][change_type] += 1\n",
    "    if(change_type=='commit'):\n",
    "        for item in items:\n",
    "                if since<=item['author_date'].date()<=until:\n",
    "                    analysis[item['repo']][change_type] += 1\n",
    "    if(change_type=='pull_request'):\n",
    "        for item in items:\n",
    "            if item['state']=='open':\n",
    "                if since<=item['created_date'].date()<=until:\n",
    "                    analysis[item['repo']][change_type] += 1\n",
    "          \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Activities in Last three months:\n",
      "https://github.com/omegaup/omegaup    issue    45\n",
      "https://github.com/omegaup/omegaup    commit    143\n",
      "https://github.com/omegaup/omegaup    pull_request    2\n",
      "https://github.com/Submitty/Submitty    issue    63\n",
      "https://github.com/Submitty/Submitty    commit    398\n",
      "https://github.com/Submitty/Submitty    pull_request    31\n",
      "https://github.com/fossasia/susi_server    issue    5\n",
      "https://github.com/fossasia/susi_server    commit    37\n",
      "https://github.com/fossasia/susi_server    pull_request    0\n",
      "https://github.com/streetmix/streetmix    issue    11\n",
      "https://github.com/streetmix/streetmix    commit    329\n",
      "https://github.com/streetmix/streetmix    pull_request    4\n"
     ]
    }
   ],
   "source": [
    "print(\"Activities in Last three months:\")\n",
    "for repo,items in analysis.items():\n",
    "    for item in items:\n",
    "        print(repo,\"  \",item,\"  \",analysis[repo][item])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unsorted Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'https://github.com/Submitty/Submitty': {'commit': 398,\n",
       "  'issue': 63,\n",
       "  'pull_request': 31},\n",
       " 'https://github.com/fossasia/susi_server': {'commit': 37,\n",
       "  'issue': 5,\n",
       "  'pull_request': 0},\n",
       " 'https://github.com/omegaup/omegaup': {'commit': 143,\n",
       "  'issue': 45,\n",
       "  'pull_request': 2},\n",
       " 'https://github.com/streetmix/streetmix': {'commit': 329,\n",
       "  'issue': 11,\n",
       "  'pull_request': 4}}"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting by sum of the issue, pull_request and commit count.\n",
    "\n",
    "Using Sorted function and lambda function.<br>\n",
    "Passing the sum of issue count, pull_request count and commit count for sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_sum = sorted(analysis.items(), key=lambda repo: (repo[1][\"issue\"]) + (repo[1][\"pull_request\"]) + (repo[1][\"commit\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing CSV\n",
    "\n",
    "Using csv module to write the activities quarterwise in the CSV file.\n",
    "\n",
    "#### fields = ['Repo', 'No. of Commits', 'No. of PRs', 'No. of Issues']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = ['Repo', 'No. of Commits', 'No. of PRs', 'No. of Issues']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://github.com/fossasia/susi_server', 37, 0, 5]\n",
      "['https://github.com/omegaup/omegaup', 143, 2, 45]\n",
      "['https://github.com/streetmix/streetmix', 329, 4, 11]\n",
      "['https://github.com/Submitty/Submitty', 398, 31, 63]\n"
     ]
    }
   ],
   "source": [
    "for item in sorted_by_sum:\n",
    "        print([item[0],item[1]['commit'],item[1]['pull_request'],\n",
    "                         item[1]['issue']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('microtask4-analysis.csv', 'w') as file:\n",
    "    writer = csv.writer(file,quoting=csv.QUOTE_MINIMAL) \n",
    "    writer.writerow(fields)\n",
    "    for item in sorted_by_sum:\n",
    "        writer.writerow([item[0],item[1]['commit'],item[1]['pull_request'],\n",
    "                         item[1]['issue']])\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Printing CSV into table form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabulate import tabulate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------  --------------  ----------  -------------\n",
      "Repo                                     No. of Commits  No. of PRs  No. of Issues\n",
      "https://github.com/fossasia/susi_server  37              0           5\n",
      "https://github.com/omegaup/omegaup       143             2           45\n",
      "https://github.com/streetmix/streetmix   329             4           11\n",
      "https://github.com/Submitty/Submitty     398             31          63\n",
      "---------------------------------------  --------------  ----------  -------------\n"
     ]
    }
   ],
   "source": [
    "with open('microtask4-analysis.csv','r', newline='') as File:  \n",
    "    reader = csv.reader(File)\n",
    "    print(tabulate(reader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
